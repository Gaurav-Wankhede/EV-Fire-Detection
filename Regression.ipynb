{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "SM5ttcbW3s0j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "from scipy.stats import truncnorm\n",
        "import warnings\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5LeYT0k4HzW"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "DZJ8IV0537oE"
      },
      "outputs": [],
      "source": [
        "file_path = 'Multiple Classification - EV Battery Faults Dataset.xlsx'\n",
        "df = pd.read_excel(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rApnAEXo6Eae"
      },
      "source": [
        "## Step 1: Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqYlGQsn6NjI",
        "outputId": "935eb7e0-a849-4358-d47b-59e22e23db0f"
      },
      "outputs": [],
      "source": [
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst 5 Rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling Negative SOC Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['SoC'] = df['SoC'].apply(lambda x: x if x >= 0 else np.nan)\n",
        "df['SoC'].fillna(df['SoC'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Temperature'] = df['Temperature'] - 273.15\n",
        "df['Voltage'] = np.clip(df['Voltage'], 48, 72)\n",
        "df['SoC'] = np.clip(df['SoC'], 0, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Battery specifications based on IEC 62133 and EN 15194 standards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Battery specifications based on IEC 62133 and EN 15194 standards\n",
        "BATTERY_SPECS = {\n",
        "    '36V': {\n",
        "        'min_voltage': 30,\n",
        "        'nominal_voltage': 36,\n",
        "        'max_voltage': 42,\n",
        "        'capacity': 10,  # Ah\n",
        "        'charge_current_range': (2, 5),  # 0.2C to 0.5C\n",
        "        'discharge_current_range': (10, 20),  # 1C to 2C\n",
        "    },\n",
        "    '48V': {\n",
        "        'min_voltage': 40,\n",
        "        'nominal_voltage': 48,\n",
        "        'max_voltage': 54.6,\n",
        "        'capacity': 10,  # Ah\n",
        "        'charge_current_range': (2, 5),\n",
        "        'discharge_current_range': (10, 20),\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Temperature limits from standards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temperature limits from standards\n",
        "TEMP_LIMITS = {\n",
        "    'operating': {'min': 0, 'max': 45},\n",
        "    'charging': {'min': 0, 'max': 40},\n",
        "    'storage': {'min': -20, 'max': 60}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select battery system (36V or 48V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select battery system (36V or 48V)\n",
        "battery_type = '36V'\n",
        "specs = BATTERY_SPECS[battery_type]\n",
        "\n",
        "# Define operating parameters\n",
        "min_voltage = specs['min_voltage']\n",
        "max_voltage = specs['max_voltage']\n",
        "nominal_voltage = specs['nominal_voltage']\n",
        "min_current = specs['discharge_current_range'][0]\n",
        "max_current = specs['discharge_current_range'][1]\n",
        "min_temp = TEMP_LIMITS['operating']['min']\n",
        "max_temp = TEMP_LIMITS['operating']['max']\n",
        "min_soc = 10  # Minimum safe SoC per industry standards\n",
        "max_soc = 90  # Maximum recommended SoC for longevity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate Resistance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def calculate_resistance(voltage, temperature, soc):\n",
        "    # Base resistance calculation\n",
        "    nominal_resistance = nominal_voltage / specs['discharge_current_range'][0]\n",
        "    \n",
        "    # Temperature compensation (based on lithium-ion characteristics)\n",
        "    temp_factor = 1 + 0.004 * (temperature - 25)  # 0.4%/Â°C temperature coefficient\n",
        "    \n",
        "    # SoC compensation\n",
        "    soc_factor = 1 + 0.1 * ((100 - soc) / 100)  # Resistance increases at lower SoC\n",
        "    \n",
        "    return nominal_resistance * temp_factor * soc_factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating Sample Data\n",
        "num_samples = 100000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to generate data following a truncated Gaussian distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to generate data following a truncated Gaussian distribution\n",
        "def generate_truncated_bell_curve_data(median, std, min_val, max_val, num_samples):\n",
        "    lower_bound = (min_val - median) / std\n",
        "    upper_bound = (max_val - median) / std\n",
        "    data = truncnorm.rvs(lower_bound, upper_bound, loc=median, scale=std, size=num_samples)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate synthetic data for SoC, Temperature, and Voltage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [],
      "source": [
        "synthetic_data = {\n",
        "    'SoC': generate_truncated_bell_curve_data(50, 20, min_soc, max_soc, num_samples),\n",
        "    'Temperature': generate_truncated_bell_curve_data(25, 10, min_temp, max_temp, num_samples),\n",
        "    'Voltage': generate_truncated_bell_curve_data(nominal_voltage, 2, min_voltage, max_voltage, num_samples)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create synthetic DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataFrame and calculate parameters\n",
        "synthetic_df = pd.DataFrame(synthetic_data)\n",
        "synthetic_df['Resistance'] = synthetic_df.apply(\n",
        "    lambda row: calculate_resistance(row['Voltage'], row['Temperature'], row['SoC']), \n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate Current using Ohm's Law with average resistance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate current using Ohm's Law\n",
        "synthetic_df['Current'] = synthetic_df['Voltage'] / synthetic_df['Resistance']\n",
        "synthetic_df['Current'] = np.clip(synthetic_df['Current'], min_current, max_current)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_risk_factors(row):\n",
        "    \"\"\"Calculate risk factors based on IEC 62133 safety requirements\"\"\"\n",
        "    risk_score = 0\n",
        "    \n",
        "    # Temperature risk (weighted: 0.4)\n",
        "    if row['Temperature'] > 40:\n",
        "        risk_score += 0.4 * ((row['Temperature'] - 40) / 5)\n",
        "    elif row['Temperature'] < 5:\n",
        "        risk_score += 0.4 * ((5 - row['Temperature']) / 5)\n",
        "        \n",
        "    # Voltage risk (weighted: 0.3)\n",
        "    if row['Voltage'] > specs['max_voltage'] - 0.5:\n",
        "        risk_score += 0.3\n",
        "    elif row['Voltage'] < specs['min_voltage'] + 2:\n",
        "        risk_score += 0.3\n",
        "        \n",
        "    # Current risk (weighted: 0.2)\n",
        "    if row['Current'] > specs['discharge_current_range'][1] * 0.9:\n",
        "        risk_score += 0.2 * ((row['Current'] - specs['discharge_current_range'][1] * 0.9) / \n",
        "                            (specs['discharge_current_range'][1] * 0.1))\n",
        "        \n",
        "    # SoC risk (weighted: 0.1)\n",
        "    if row['SoC'] < 15 or row['SoC'] > 85:\n",
        "        risk_score += 0.1\n",
        "        \n",
        "    return np.clip(risk_score, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Clip Current\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate fire risk\n",
        "synthetic_df['Fire_Risk'] = synthetic_df.apply(calculate_risk_factors, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combine original and synthetic datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine original and synthetic datasets\n",
        "df = pd.concat([df, synthetic_df], ignore_index=True)\n",
        "\n",
        "print(f\"Shape after adding synthetic data: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Outlier handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Temperature'] = np.clip(df['Temperature'], min_temp, max_temp)\n",
        "df['Voltage'] = np.clip(df['Voltage'], min_voltage, max_voltage)\n",
        "df['SoC'] = np.clip(df['SoC'], min_soc, max_soc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Remove Label column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop(columns=['Label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export the combined dataset to a CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the combined dataset to a CSV file\n",
        "try:\n",
        "    os.makedirs(\"data\", exist_ok=True)\n",
        "    df.to_csv(\"data/combined_dataset.csv\", index=False)\n",
        "    print(\"\\nCombined dataset exported to data/combined_dataset.csv\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nError exporting combined dataset: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualze distribution after outlier handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualze distribution after outlier handling\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "# SoC distribution\n",
        "plt.subplot(4, 1, 1)\n",
        "sns.histplot(df['SoC'], kde=True, bins=30)\n",
        "plt.title('Distribution of State of Charge (SoC)')\n",
        "\n",
        "# Temperature distribution\n",
        "plt.subplot(4, 1, 2)\n",
        "sns.histplot(df['Temperature'], kde=True, bins=30)\n",
        "plt.title('Distribution of Temperature')\n",
        "\n",
        "# Voltage distribution\n",
        "plt.subplot(4, 1, 3)\n",
        "sns.histplot(df['Voltage'], kde=True, bins=30)\n",
        "plt.title('Distribution of Voltage')\n",
        "\n",
        "# Current distribution\n",
        "plt.subplot(4, 1, 4)\n",
        "sns.histplot(df['Current'], kde=True, bins=30)\n",
        "plt.title('Distribution of Current')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Current vs Voltage scatterplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.subplot(4, 2, (5,6))\n",
        "plt.scatter(df['Voltage'], df['Current'], alpha=0.5)\n",
        "plt.xlabel('Voltage')\n",
        "plt.ylabel('Current')\n",
        "plt.title('Current vs Voltage')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "VmDlILQa65uZ",
        "outputId": "16314aba-3793-43ce-9fe6-811e5004883e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "corr_matrix = df[['SoC', 'Temperature', 'Voltage', 'Current']].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix (Outliers Handled)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtJZx4Li4Xqm"
      },
      "source": [
        "## Step 2: Define Fire Risk Thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "_1Wedm0j4U-1"
      },
      "outputs": [],
      "source": [
        "# Define Fire Risk Thresholds\n",
        "temp_threshold = 40  # High temperature threshold, slightly below max\n",
        "voltage_low_threshold = 50  # Low voltage threshold, slightly above min\n",
        "voltage_high_threshold = 70  # High voltage threshold, slightly below max\n",
        "soc_low_threshold = 60  # Low SOC threshold, slightly above min\n",
        "soc_high_threshold = 95  # High SOC threshold, slightly below max\n",
        "current_low_threshold = 31 # Low current threshold, slightly above min\n",
        "current_high_threshold = 35 # High current threshold, slightly below max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBEd4zto4XKF"
      },
      "source": [
        "# Step 3: Analyze the Dataset and Add Fire Risk Column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slNGDAyU4xEa"
      },
      "source": [
        "### Conditions for Fire Risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "Z-9XLngS4sXk"
      },
      "outputs": [],
      "source": [
        "# Conditions for Fire Risk\n",
        "def create_features(df):\n",
        "    # Original features\n",
        "    features = df[['SoC', 'Temperature', 'Voltage', 'Current']].copy()\n",
        "    \n",
        "    # Add interaction terms\n",
        "    features['Temp_Voltage'] = df['Temperature'] * df['Voltage']\n",
        "    features['Temp_SoC'] = df['Temperature'] * df['SoC']\n",
        "    features['Voltage_SoC'] = df['Voltage'] * df['SoC']\n",
        "    features['Temp_Current'] = df['Temperature'] * df['Current']\n",
        "    features['Voltage_Current'] = df['Voltage'] * df['Current']\n",
        "    features['SoC_Current'] = df['SoC'] * df['Current']\n",
        "\n",
        "    # Add polynomial terms\n",
        "    features['Temp_Squared'] = df['Temperature'] ** 2\n",
        "    features['Voltage_Squared'] = df['Voltage'] ** 2\n",
        "    features['SoC_Squared'] = df['SoC'] ** 2\n",
        "    features['Current_Squared'] = df['Current'] ** 2\n",
        "\n",
        "    # Add threshold-based features\n",
        "    features['High_Temp'] = (df['Temperature'] > temp_threshold).astype(int)\n",
        "    features['Low_Voltage'] = (df['Voltage'] < voltage_low_threshold).astype(int)\n",
        "    features['High_Voltage'] = (df['Voltage'] > voltage_high_threshold).astype(int)\n",
        "    features['Low_SoC'] = (df['SoC'] < soc_low_threshold).astype(int)\n",
        "    features['High_SoC'] = (df['SoC'] > soc_high_threshold).astype(int)\n",
        "    features['Low_Current'] = (df['Current'] < current_low_threshold).astype(int)\n",
        "    features['High_Current'] = (df['Current'] > current_high_threshold).astype(int)\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_fire_risk_score(df):\n",
        "    risk_score = np.zeros(len(df))\n",
        "    \n",
        "    # Temperature risk (exponential increase after threshold)\n",
        "    temp_risk = np.exp((df['Temperature'] - temp_threshold) / 10) / np.exp(5.5)  # Normalized\n",
        "    risk_score += np.clip(temp_risk, 0, 0.4)\n",
        "    \n",
        "    # Voltage risk (both low and high voltage are risky)\n",
        "    voltage_low_risk = np.exp((voltage_low_threshold - df['Voltage']) * 2) / np.exp(5)\n",
        "    voltage_high_risk = np.exp((df['Voltage'] - voltage_high_threshold) * 2) / np.exp(5)\n",
        "    risk_score += np.clip(voltage_low_risk + voltage_high_risk, 0, 0.3)\n",
        "    \n",
        "    # SoC risk (both very low and very high are risky)\n",
        "    soc_low_risk = np.exp((soc_low_threshold - df['SoC']) / 20) / np.exp(1)\n",
        "    soc_high_risk = np.exp((df['SoC'] - soc_high_threshold) / 10) / np.exp(1)\n",
        "    risk_score += np.clip(soc_low_risk + soc_high_risk, 0, 0.3)\n",
        "    \n",
        "    # Current risk (both low and high current are risky)\n",
        "    current_low_risk = np.exp((current_low_threshold - df['Current']) * 2) / np.exp(5)\n",
        "    current_high_risk = np.exp((df['Current'] - current_high_threshold) * 2) / np.exp(5)\n",
        "    risk_score += np.clip(current_low_risk + current_high_risk, 0, 0.3)\n",
        "    \n",
        "    # Normalize to [0, 1]\n",
        "    risk_score = np.clip(risk_score, 0, 1)\n",
        "    \n",
        "    # Assign to new column\n",
        "    df['Fire Risk Score'] = risk_score\n",
        "    \n",
        "    # Print summary statistics of the risk scores\n",
        "    print(\"\\nFire Risk Score Statistics:\")\n",
        "    print(df['Fire Risk Score'].describe())\n",
        "    \n",
        "    # Print distribution of risk scores\n",
        "    print(\"\\nRisk Score Distribution:\")\n",
        "    risk_bins = pd.cut(df['Fire Risk Score'], \n",
        "                      bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
        "                      labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
        "    print(risk_bins.value_counts().sort_index())\n",
        "    \n",
        "    return df['Fire Risk Score']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HIr_B6L7r_a"
      },
      "source": [
        "## Step 5: Train Model to Predict Fire Risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etJ7saGD7beM"
      },
      "outputs": [],
      "source": [
        "# Create features and target\n",
        "X = create_features(df)\n",
        "y = calculate_fire_risk_score(df)\n",
        "\n",
        "# Optional: Print some examples\n",
        "print(\"\\nSample data with Fire Risk Scores:\")\n",
        "print(df[['Temperature', 'Voltage', 'SoC', 'Current', 'Fire Risk Score']].head(10).round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "IjR6D1wW70B9"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "voWC09AB73FY"
      },
      "outputs": [],
      "source": [
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swJeSZ449tuO"
      },
      "source": [
        "### Define a Function to Evaluate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "-rfv8gAk9wkJ"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_train, y_train, X_test, y_test, threshold=0.5):\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    train_scores = []\n",
        "    val_scores = []\n",
        "    for train_index, val_index in kf.split(X_train):\n",
        "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "        model.fit(X_train_fold, y_train_fold)\n",
        "        y_train_pred = model.predict(X_train_fold)\n",
        "        y_val_pred = model.predict(X_val_fold)\n",
        "        train_scores.append(mean_squared_error(y_train_fold, y_train_pred))\n",
        "        val_scores.append(mean_squared_error(y_val_fold, y_val_pred))\n",
        "    \n",
        "    train_mse = np.mean(train_scores)\n",
        "    val_mse = np.mean(val_scores)\n",
        "    print(f\"Cross-Validation Training MSE: {train_mse:.4f}\")\n",
        "    print(f\"Cross-Validation Validation MSE: {val_mse:.4f}\")\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"  Test MSE: {mse:.4f}\")\n",
        "    print(f\"  Test R2: {r2:.4f}\")\n",
        "    \n",
        "    y_pred_class = (y_pred >= threshold).astype(int)\n",
        "    cm = confusion_matrix(y_test >= threshold, y_pred_class)\n",
        "    print(\"  Confusion Matrix:\\n\", cm)\n",
        "    print(\"  Classification Report:\\n\", classification_report(y_test >= threshold, y_pred_class))\n",
        "    \n",
        "    fpr, tpr, thresholds = roc_curve(y_test >= threshold, y_pred)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC)')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"-\" * 60)\n",
        "    return train_mse, val_mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter Tuning with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "kkSffyeZ92a6",
        "outputId": "b2d2636c-527f-4d15-9a1f-3fe8686022af"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "param_distributions = {\n",
        "    'Linear Regression': {},\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [10, 15, 20],\n",
        "        'min_samples_split': [10, 20],\n",
        "        'min_samples_leaf': [2, 4],\n",
        "        'max_features': ['sqrt', 'log2']\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [2, 3, 4],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'min_samples_split': [5, 10],\n",
        "        'min_samples_leaf': [2, 4]\n",
        "    }\n",
        "}\n",
        "\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "best_models = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Tuning {name}:\")\n",
        "    if param_distributions[name]:\n",
        "        random_search = RandomizedSearchCV(\n",
        "            model,\n",
        "            param_distributions[name],\n",
        "            n_iter=50,\n",
        "            cv=5,\n",
        "            scoring='neg_mean_squared_error',\n",
        "            n_jobs=-1,\n",
        "            random_state=42\n",
        "        )\n",
        "        random_search.fit(X_train_split, y_train_split)\n",
        "        print(\"Best Parameters:\")\n",
        "        print(random_search.best_params_)\n",
        "        best_models[name] = random_search.best_estimator_\n",
        "    else:\n",
        "        model.fit(X_train_split, y_train_split)\n",
        "        best_models[name] = model\n",
        "\n",
        "# Evaluate models and select the best one\n",
        "best_model_name = None\n",
        "best_model = None\n",
        "best_mse = float('inf')\n",
        "overfitting_threshold = 0.0005  # Define your overfitting threshold\n",
        "\n",
        "model_results = []\n",
        "\n",
        "for name, model in best_models.items():\n",
        "    print(f\"{name}:\")\n",
        "    train_mse, val_mse = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
        "    model_results.append((name, model, train_mse, val_mse))\n",
        "\n",
        "model_results.sort(key=lambda x: x[3]) # Sort by validation MSE\n",
        "\n",
        "for name, model, train_mse, val_mse in model_results:\n",
        "    if (train_mse - val_mse) > overfitting_threshold:\n",
        "        print(f\"{name} is overfitting. Considering a simpler model.\")\n",
        "    else:\n",
        "        best_model_name = name\n",
        "        best_model = model\n",
        "        best_mse = val_mse\n",
        "        print(f\"Best Model: {best_model_name}\")\n",
        "        print(f\"Best Validation MSE: {best_mse:.4f}\")\n",
        "        break # Select the first non-overfitting model\n",
        "else:\n",
        "    # If no model is found to be non-overfitting, select the best model based on validation MSE\n",
        "    best_model_name, best_model, _, best_mse = model_results[0]\n",
        "    print(f\"No non-overfitting model found. Selecting best model based on validation MSE: {best_model_name}\")\n",
        "    print(f\"Best Validation MSE: {best_mse:.4f}\")\n",
        "\n",
        "# Final evaluation on test set\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred_best)\n",
        "r2 = r2_score(y_test, y_pred_best)\n",
        "print(f\"Test MSE for Best Model: {mse:.4f}\")\n",
        "print(f\"Test R2 for Best Model: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataFrame with actual and predicted values\n",
        "results_df = pd.DataFrame({\n",
        "    'Actual_Risk': y_test,\n",
        "    'Predicted_Risk': y_pred_best,\n",
        "    'Difference': np.abs(y_test - y_pred_best)\n",
        "})\n",
        "\n",
        "# Add original features for analysis\n",
        "test_features = pd.DataFrame(X_test, columns=X.columns)\n",
        "results_df = pd.concat([results_df, test_features], axis=1)\n",
        "\n",
        "# Add some useful statistics\n",
        "print(\"\\nPrediction Analysis:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"\\nSummary Statistics of Predictions:\")\n",
        "print(results_df[['Actual_Risk', 'Predicted_Risk', 'Difference']].describe())\n",
        "\n",
        "# Show distribution of predictions\n",
        "print(\"\\nDistribution of Predictions:\")\n",
        "print(pd.cut(results_df['Predicted_Risk'], \n",
        "            bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0], \n",
        "            labels=['Very Low', 'Low', 'Medium', 'High', 'Very High']).value_counts())\n",
        "\n",
        "# Show some example predictions\n",
        "print(\"\\nSample Predictions (10 random examples):\")\n",
        "sample_results = results_df.sample(10)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "print(sample_results.round(3))\n",
        "\n",
        "# Print cases with largest prediction errors\n",
        "print(\"\\nCases with Largest Prediction Errors:\")\n",
        "print(results_df.nlargest(5, 'Difference').round(3))\n",
        "\n",
        "# Save results to CSV for further analysis\n",
        "results_df.to_csv('model/prediction_analysis.csv', index=False)\n",
        "print(\"\\nDetailed results saved to 'prediction_analysis.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualization subplot\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Actual vs Predicted\n",
        "plt.subplot(131)\n",
        "plt.scatter(y_test, y_pred_best, alpha=0.5)\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlabel('Actual Risk Score')\n",
        "plt.ylabel('Predicted Risk Score')\n",
        "plt.title('Actual vs Predicted Risk Scores')\n",
        "\n",
        "# Plot 2: Distribution of predictions\n",
        "plt.subplot(132)\n",
        "sns.histplot(data=results_df, x='Predicted_Risk', bins=30)\n",
        "plt.title('Distribution of Predicted Risk Scores')\n",
        "plt.xlabel('Risk Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature importance plot\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance, x='Importance', y='Feature')\n",
        "plt.title('Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create test cases\n",
        "test_cases = pd.DataFrame({\n",
        "    'Temperature': [25, 50, 75, 30, 60, 40, 80, 35, 45, 70],  # Mix of normal and high temperatures\n",
        "    'Voltage': [50, 50, 70, 60, 50, 60, 70, 50, 60, 50],  # Mix of normal, low and high voltages\n",
        "    'SoC': [50, 15, 95, 60, 25, 75, 90, 40, 85, 10],  # Mix of normal, low and high SoC values\n",
        "    'Current': [32, 31, 35, 33, 30, 34, 36, 32, 33, 31]\n",
        "})\n",
        "\n",
        "# Create features for test cases using the same feature engineering\n",
        "def create_test_features(df):\n",
        "    features = df[['SoC', 'Temperature', 'Voltage', 'Current']].copy()\n",
        "    \n",
        "    # Add interaction terms\n",
        "    features['Temp_Voltage'] = df['Temperature'] * df['Voltage']\n",
        "    features['Temp_SoC'] = df['Temperature'] * df['SoC']\n",
        "    features['Voltage_SoC'] = df['Voltage'] * df['SoC']\n",
        "    features['Temp_Current'] = df['Temperature'] * df['Current']\n",
        "    features['Voltage_Current'] = df['Voltage'] * df['Current']\n",
        "    features['SoC_Current'] = df['SoC'] * df['Current']\n",
        "    \n",
        "    # Add polynomial terms\n",
        "    features['Temp_Squared'] = df['Temperature'] ** 2\n",
        "    features['Voltage_Squared'] = df['Voltage'] ** 2\n",
        "    features['SoC_Squared'] = df['SoC'] ** 2\n",
        "    features['Current_Squared'] = df['Current'] ** 2\n",
        "    \n",
        "    # Add threshold-based features\n",
        "    features['High_Temp'] = (df['Temperature'] > temp_threshold).astype(int)\n",
        "    features['Low_Voltage'] = (df['Voltage'] < voltage_low_threshold).astype(int)\n",
        "    features['High_Voltage'] = (df['Voltage'] > voltage_high_threshold).astype(int)\n",
        "    features['Low_SoC'] = (df['SoC'] < soc_low_threshold).astype(int)\n",
        "    features['High_SoC'] = (df['SoC'] > soc_high_threshold).astype(int)\n",
        "    features['Low_Current'] = (df['Current'] < current_low_threshold).astype(int)\n",
        "    features['High_Current'] = (df['Current'] > current_high_threshold).astype(int)\n",
        "    \n",
        "    return features\n",
        "\n",
        "# Process test cases\n",
        "X_test_cases = create_test_features(test_cases)\n",
        "X_test_cases_scaled = scaler.transform(X_test_cases)\n",
        "y_pred_test = best_model.predict(X_test_cases_scaled)\n",
        "\n",
        "# Add predictions to test cases\n",
        "test_cases['Predicted_Risk'] = y_pred_test\n",
        "\n",
        "# Add risk level categorization\n",
        "def get_risk_level(score):\n",
        "    if score <= 0.2:\n",
        "        return 'Very Low'\n",
        "    elif score <= 0.4:\n",
        "        return 'Low'\n",
        "    elif score <= 0.6:\n",
        "        return 'Medium'\n",
        "    elif score <= 0.8:\n",
        "        return 'High'\n",
        "    else:\n",
        "        return 'Very High'\n",
        "\n",
        "test_cases['Risk_Level'] = test_cases['Predicted_Risk'].apply(get_risk_level)\n",
        "\n",
        "# Display results\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "print(\"\\nTest Case Results:\")\n",
        "print(\"-\" * 80)\n",
        "print(test_cases.round(3))\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nRisk Level Distribution:\")\n",
        "print(test_cases['Risk_Level'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize results\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Risk scores for each test case\n",
        "plt.subplot(131)\n",
        "plt.bar(range(len(test_cases)), test_cases['Predicted_Risk'])\n",
        "plt.xlabel('Test Case')\n",
        "plt.ylabel('Predicted Risk Score')\n",
        "plt.title('Risk Scores by Test Case')\n",
        "\n",
        "# Plot 2: Risk scores vs Temperature\n",
        "plt.subplot(132)\n",
        "plt.scatter(test_cases['Temperature'], test_cases['Predicted_Risk'])\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Predicted Risk Score')\n",
        "plt.title('Risk Score vs Temperature')\n",
        "\n",
        "# Plot 3: Risk scores vs SoC\n",
        "plt.subplot(133)\n",
        "plt.scatter(test_cases['SoC'], test_cases['Predicted_Risk'])\n",
        "plt.xlabel('State of Charge (SoC)')\n",
        "plt.ylabel('Predicted Risk Score')\n",
        "plt.title('Risk Score vs SoC')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed analysis for high-risk cases\n",
        "print(\"\\nHigh Risk Cases (Risk Score > 0.6):\")\n",
        "print(\"-\" * 80)\n",
        "high_risk_cases = test_cases[test_cases['Predicted_Risk'] > 0.6]\n",
        "if len(high_risk_cases) > 0:\n",
        "    print(high_risk_cases.round(3))\n",
        "else:\n",
        "    print(\"No high risk cases found in the test set\")\n",
        "\n",
        "# Print correlation analysis\n",
        "print(\"\\nCorrelation with Risk Score:\")\n",
        "print(\"-\" * 80)\n",
        "correlations = test_cases[['Temperature', 'Voltage', 'SoC', 'Predicted_Risk']].corr()['Predicted_Risk'].sort_values(ascending=False)\n",
        "print(correlations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Pickle File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the 'model' directory if it doesn't exist\n",
        "model_dir = \"model\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Export the model\n",
        "with open(os.path.join(model_dir, 'fire_risk_model.pkl'), 'wb') as file:\n",
        "    pickle.dump(best_model, file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
